{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10c38b7c",
   "metadata": {},
   "source": [
    "# LLMs: Chat Models\n",
    "\n",
    "Chat models are a variation on language models. While chat models use language models under the hood, the interface they expose is a bit different. Rather than expose a \"text in, text out\" API, they expose an interface where \"chat messages\" are the inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47445a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f1eefb",
   "metadata": {},
   "source": [
    "the Chat model interface is based around messages rather that raw text. LangChain are `AIMessage`, `HumanMessage`, `SystemMessage`, and `ChatMessage` -- `ChatMessage` takes in an arbitrary role parameter. Most of the time, you'll just be dealing with `HumanMessage`, `AIMessage`, and `SystemMessage`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07842ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'adore programmer.\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "chat([HumanMessage(\n",
    "    content=\"Translate this sentence from English to French: I love programming.\"\n",
    ")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8661027",
   "metadata": {},
   "source": [
    "You can also send it as system messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05b472ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'adore la programmation.\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant that translates English to French.\"),\n",
    "    HumanMessage(content=\"I love programming.\")\n",
    "]\n",
    "chat(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab09ff3f",
   "metadata": {},
   "source": [
    "You can use `generate()` like in completion for batch calls and richer outputs. It returns an `ChatResult` which contains `ChatGenerations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1410a858",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_messages = [\n",
    "    [\n",
    "        SystemMessage(content=\"You are a helpful assistant that translates English to French.\"),\n",
    "        HumanMessage(content=\"I love programming.\")\n",
    "    ],\n",
    "    [\n",
    "        SystemMessage(content=\"You are a helpful assistant that translates English to French.\"),\n",
    "        HumanMessage(content=\"I love artificial intelligence.\")\n",
    "    ],\n",
    "]\n",
    "result = chat.generate(batch_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edf91be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"J'adore la programmation.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_g = result.generations[0][0]\n",
    "\n",
    "chat_g.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f805cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'adore la programmation.\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_g.message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b854b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_g.generation_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffacf15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'prompt_tokens': 53,\n",
       "  'completion_tokens': 20,\n",
       "  'total_tokens': 73},\n",
       " 'model_name': 'gpt-3.5-turbo'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.llm_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceab930c",
   "metadata": {},
   "source": [
    "### *can you use chat_prompts in non-chat models?*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68e8c5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are a helpful assistant that translates English to French.\n",
      "Human: I love programming.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\nSystem: J'adore le programmation.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "print(prompt.format())\n",
    "llm = OpenAI()\n",
    "llm(prompt.format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3e47d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Translate this sentence from English to French: I love programming.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nJe adore la programmation.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "without_system_message = [HumanMessage(\n",
    "    content=\"Translate this sentence from English to French: I love programming.\"\n",
    ")]\n",
    "prompt = ChatPromptTemplate.from_messages(without_system_message)\n",
    "print(prompt.format())\n",
    "\n",
    "llm(prompt.format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8063bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
