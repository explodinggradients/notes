{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "800cb413",
   "metadata": {},
   "source": [
    "# Building QA Systems with Langchain\n",
    "\n",
    "Building QA systems consists of the following steps\n",
    "![](https://python.langchain.com/assets/images/qa_flow-9fbd91de9282eb806bda1c6db501ecec.jpeg)\n",
    "\n",
    "but lets start with a quick example to see things in actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "858d075e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "\n",
    "loader = TextLoader(\"nyc_text.txt\")\n",
    "index = VectorstoreIndexCreator().from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7251aaf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' New York City was named after King Charles II of England, who granted the lands to his brother, the Duke of York.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"How did New York City get its name?\"\n",
    "index.query(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce3c36f",
   "metadata": {},
   "source": [
    "In this example we build a QA system with just 3 lines of code. Langchain does all of the above steps under the hood for you.\n",
    "\n",
    "But we're here to study the internals of langchain, so lets take a look at the internals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db473643",
   "metadata": {},
   "source": [
    "## 1. Load Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d45d1245",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "\n",
    "loader = TextLoader(\"nyc_text.txt\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d876a62a",
   "metadata": {},
   "source": [
    "This returns a list of `Documents` which contain the text we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58c713c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344d8631",
   "metadata": {},
   "source": [
    "## 2. Transform Documents\n",
    "\n",
    "with the docs loaded what you want to do now is transform it into formats that make it easier to work with. One common strategy we do is splitting the doc into smaller chunks that can be passed into the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b864850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "all_splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a29a187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10187177",
   "metadata": {},
   "source": [
    "## 3. Store\n",
    "\n",
    "Now we can store them somewhere where it can be easily retrieved. If your thinking about Databases now your right. We will be using a special kind of DB called VectorDBs which store the vector representations of the chunks we just made above. This makes it easier to retrieve the required ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdc5946b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8a9be9",
   "metadata": {},
   "source": [
    "## 4. Retrieve\n",
    "\n",
    "All the steps until now was for preparing and storing the data you have so that at query time we can retrieve it and pass it to the LLM for it to use.\n",
    "\n",
    "The first step at query time is to get the relevent documents which we do be getting the most similar texts to the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45effcf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = vectorstore.similarity_search(question)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a79f3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjmachan/.pyenv/versions/3.10.12/envs/notes/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.retrievers import SVMRetriever\n",
    "\n",
    "svm_retriever = SVMRetriever.from_documents(all_splits,OpenAIEmbeddings())\n",
    "docs_svm=svm_retriever.get_relevant_documents(question)\n",
    "len(docs_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133f7a53",
   "metadata": {},
   "source": [
    "explore\n",
    "- SVM retriever\n",
    "- MMR\n",
    "- MultiQueryRetriver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d2c0f9",
   "metadata": {},
   "source": [
    "## 5. Generate\n",
    "\n",
    "Here pass the retrieved texts to the LLM so that it can use it to answer the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b25f630a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'How did New York City get its name?',\n",
       " 'result': 'New York City was named in honor of the Duke of York, who would later become King James II of England. In 1664, King Charles II appointed the Duke as the proprietor of the former territory of New Netherland, including the city of New Amsterdam, when England seized it from Dutch control.'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectorstore.as_retriever()\n",
    ")\n",
    "result = qa_chain({\"query\": question})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fd05ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York City was named in honor of the Duke of York, who would later become King James II of England. In 1664, King Charles II appointed the Duke as the proprietor of the former territory of New Netherland, including the city of New Amsterdam, when England seized it from Dutch control.\n"
     ]
    }
   ],
   "source": [
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a51ff3",
   "metadata": {},
   "source": [
    "You can also change the prompt easily like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b1f768f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Arrr! New York City got its name in honor of the Duke of York, who later became King James II of England. Arrr!'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. \n",
    "Answer as if you are a pirate and say \"Arrr!\" at the end.\n",
    "\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804e58ab",
   "metadata": {},
   "source": [
    "if you want to retrieve the source documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2ab4987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['query', 'result', 'source_documents']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    return_source_documents=True\n",
    ")\n",
    "result = qa_chain({\"query\": question})\n",
    "print(len(result['source_documents']))\n",
    "\n",
    "list(result.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4d1e3a",
   "metadata": {},
   "source": [
    "It is also helpful to return citations and to do that in langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f52ff04a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How did New York City get its name?',\n",
       " 'answer': 'New York City was named in honor of the Duke of York, who would become King James II of England. It was named in 1664 when England seized the territory of New Netherland from Dutch control. The city was originally called New Amsterdam but was renamed New York after it came under British control. \\n',\n",
       " 'sources': 'nyc_text.txt'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "\n",
    "qa_chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectorstore.as_retriever()\n",
    ")\n",
    "\n",
    "result = qa_chain({\"question\": question})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9df491",
   "metadata": {},
   "source": [
    "## 6. Converse\n",
    "\n",
    "this is actually pretty neat and an extention from other RAG systems. The ability to have a conversation with the document. other systems can implement this easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cbb91b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\", \n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bceaa088",
   "metadata": {},
   "source": [
    "We use a different chain for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fd2cebab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "chat = ConversationalRetrievalChain.from_llm(\n",
    "    llm, \n",
    "    retriever=retriever, \n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "44081e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"New York City was named in honor of the Duke of York, who would later become King James II of England. In 1664, King Charles II appointed the Duke as proprietor of the former territory of New Netherland, including the city of New Amsterdam, when England seized it from Dutch control. The Duke of York's name was then given to the city, and it became known as New York.\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = chat(\n",
    "    {\"question\": \"How did New York city get its name\"}\n",
    ")\n",
    "r[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c9b48dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Duke of York mentioned in the context is James, who later became King James II of England. He was the younger brother of King Charles II. In 1664, King Charles II appointed James as the proprietor of the territory of New Netherland, which included the city of New Amsterdam (later renamed New York). James played a significant role in the English takeover of New Amsterdam from Dutch control. He was eventually deposed in the Glorious Revolution.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = chat(\n",
    "    {\"question\": \"tell me more about the Duke of York\"}\n",
    ")\n",
    "r[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4ddda2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New Netherland was a Dutch colony established in the early 17th century in what is now the northeastern United States. It encompassed the area that would later become New York, New Jersey, Delaware, and parts of Connecticut and Pennsylvania. New Amsterdam was the capital and main settlement of New Netherland, located on the southern tip of Manhattan Island. It was founded in 1625 and later renamed New York when it came under English control in 1664.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = chat(\n",
    "    {\"question\": \"what is New Netherland and New Amsterdam\"}\n",
    ")\n",
    "r[\"answer\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
