{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcea3a96-d866-4083-9626-14450bfb5fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55763470-dcdb-49ef-9ae9-3b1e3be9343e",
   "metadata": {},
   "source": [
    "# The Problem\n",
    "\n",
    "Figure out a Metrics-driven approach to make sense of this\n",
    "![](https://media.licdn.com/dms/image/D4D22AQEgjWxKXokOPA/feedshare-shrink_800/0/1708498751086?e=1711584000&v=beta&t=xaT95vKS8m4qTybofpKqQfXOGoFs8lQXBuOk2Fr45AE)\n",
    "\n",
    "Access to the [original miro mindmap](https://miro.com/app/board/uXjVNvklNmc=/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147920f5-3448-440a-9bef-5665714df901",
   "metadata": {},
   "source": [
    "## Our Solution: `Metrics Driven Development with Ragas`\n",
    "\n",
    "![](https://docs.ragas.io/en/latest/_static/imgs/component-wise-metrics.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfc41ad4-0293-4713-b247-9666cd37593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cfe471-eb5a-48d2-832b-84d0b9d24be1",
   "metadata": {},
   "source": [
    "## VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "000582e7-5b78-4d87-9826-a589ac6f6dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the documents\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "loader = DirectoryLoader(\"./data/\")\n",
    "documents = loader.load()\n",
    "\n",
    "# add filename as metadata\n",
    "for document in documents:\n",
    "    document.metadata['file_name'] = document.metadata['source']\n",
    "\n",
    "# how many docs do we have?\n",
    "docs = documents\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aa6746f-7740-4d26-a00b-219c122c51e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# create the vector store\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8e6f109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_question</th>\n",
       "      <th>output_ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the expectations for behavior that co...</td>\n",
       "      <td>Using courteous language, being respectful and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does the concept of a presentable scope of...</td>\n",
       "      <td>The concept of a presentable scope of work hel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the importance of levelheadedness in t...</td>\n",
       "      <td>Levelheadedness is important in the company's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the process for formal performance rev...</td>\n",
       "      <td>You'll meet with your manager for formal perfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the qualifications and responsibiliti...</td>\n",
       "      <td>The qualifications and responsibilities of a S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      input_question  \\\n",
       "0  What are the expectations for behavior that co...   \n",
       "1  How does the concept of a presentable scope of...   \n",
       "2  What is the importance of levelheadedness in t...   \n",
       "3  What is the process for formal performance rev...   \n",
       "4  What are the qualifications and responsibiliti...   \n",
       "\n",
       "                                 output_ground_truth  \n",
       "0  Using courteous language, being respectful and...  \n",
       "1  The concept of a presentable scope of work hel...  \n",
       "2  Levelheadedness is important in the company's ...  \n",
       "3  You'll meet with your manager for formal perfo...  \n",
       "4  The qualifications and responsibilities of a S...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "eval_df = pd.read_csv(\"./eval_dataset.csv\").dropna(ignore_index=True)\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6567e4-4b22-405e-88f9-114b87b0e32d",
   "metadata": {},
   "source": [
    "Now you have a nice way to view them and select the ones you want."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077c8271-63ee-4d9f-ac57-9df5874a8482",
   "metadata": {},
   "source": [
    "## Baselines\n",
    "\n",
    "now lets build 2 baselines and compare them with metrics available through Ragas. The first metric will be `AnswerCorrectness`.\n",
    "\n",
    "The question I'm curious about is\n",
    "> Is RAG actually better than just LLM's for this data distribution?\n",
    "\n",
    "well - lets compare shall we! We'll take 2 examples\n",
    "1. Vanilla RAG from Langchain\n",
    "2. GPT 3.5 and my humble prompts\n",
    "\n",
    "first create both"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9728615b-14c9-4e43-8b14-8880e74fd4b4",
   "metadata": {},
   "source": [
    "### RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61a273b8-921a-4d4e-a255-2a5182f6899f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63fa1de7-6df5-4782-9c49-4c0f5a66a4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "vectorstore = FAISS.from_documents(documents, embedding=OpenAIEmbeddings())\n",
    "vectorstore_retriever = vectorstore.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    \n",
    "def ragas_output_parser(docs):\n",
    "    return [doc.page_content for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c423bf18-22e1-4898-aeff-c591556d71b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "generator = (\n",
    "    prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "retriever = RunnableParallel({\n",
    "    \"context\": vectorstore_retriever | format_docs, \n",
    "    \"question\": RunnablePassthrough(),\n",
    "})\n",
    "\n",
    "filter_langsmith_dataset = RunnableLambda(lambda x: x[\"question\"] if isinstance(x, dict) else x)\n",
    "\n",
    "rag_chain = RunnableParallel({\n",
    "    \"question\": filter_langsmith_dataset,\n",
    "    \"answer\": filter_langsmith_dataset | retriever | generator,\n",
    "    \"contexts\": filter_langsmith_dataset | vectorstore_retriever | ragas_output_parser,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84765931-c5db-4471-91be-b2bbf6bce13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:  What are the expectations for behavior that contributes to a healthy and friendly work environment according to the 37signals Code of Conduct?\n"
     ]
    }
   ],
   "source": [
    "q = eval_df.input_question[0]\n",
    "print(\"Q: \", q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c45e70b-1055-4317-bc61-80b8b8275810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The expectations for behavior that contributes to a healthy and friendly work environment according to the 37signals Code of Conduct include using courteous language, being respectful and empathetic, accepting constructive criticism, and assuming good intentions. Unacceptable behavior includes the use of sexualized or violent language, making unwelcome sexual advances, and any form of discrimination or harassment. Employees are expected to report any violations of the Code of Conduct to their manager or leadership for review and investigation.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer = RunnableLambda(lambda x: x[\"answer\"])\n",
    "resp = (rag_chain | get_answer).invoke(q)\n",
    "resp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d448d4a9-e6da-4dba-a8f4-9ae031a13167",
   "metadata": {},
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87fb71c0-622b-4cbc-99ae-c81c28c0cd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Use three sentences maximum and keep the answer as concise as possible.\n",
    "Always say \"thanks for asking!\" at the end of the answer.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "llm_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "just_llm = (\n",
    "    {\"question\": RunnablePassthrough()}\n",
    "    | llm_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    | RunnableParallel({\n",
    "        \"answer\": RunnablePassthrough(),\n",
    "        \"contexts\": RunnableLambda(lambda _: [\"\"]),\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f1ae80c-a39d-42a1-9b8d-9e101f6fb1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:  What are the expectations for behavior that contributes to a healthy and friendly work environment according to the 37signals Code of Conduct?\n"
     ]
    }
   ],
   "source": [
    "q = eval_df.input_question[0]\n",
    "print(\"Q: \", q)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e709c908-9e2d-4f2e-a664-b4df12215ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The 37signals Code of Conduct expects employees to be respectful, open-minded, and collaborative in order to contribute to a healthy and friendly work environment. It also emphasizes the importance of communication, empathy, and a positive attitude towards colleagues. Thanks for asking!'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = (just_llm | get_answer).invoke(q)\n",
    "resp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92529864-e251-4b93-b968-b885c3d2f058",
   "metadata": {},
   "source": [
    "# Evaluate: just_llm vs rag_chain\n",
    "\n",
    "Let evaluate and compare with just_llm and rag_chain. We have some utility functions to help us with this.\n",
    "\n",
    "First is `EvaluatorChain` which is a wrapper around a langsmith evaluator that can be used to evaluate a langchain runnable.\n",
    "\n",
    "Second is `evaluate` which run the evaluations for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d43007aa-3e80-4039-b4e5-cff030bb89c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.integrations.langsmith import evaluate\n",
    "\n",
    "from ragas.metrics import answer_correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8399a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'just_llm' at:\n",
      "https://smith.langchain.com/o/9bfbddc5-b88e-41e5-92df-2a62f0c64b4b/datasets/8f267706-24b2-47fb-84ee-3ea3cfc5a0c0/compare?selectedSessions=ec853c9b-906e-43b0-8b61-676f4348fdea\n",
      "\n",
      "View all tests for Dataset basecamp at:\n",
      "https://smith.langchain.com/o/9bfbddc5-b88e-41e5-92df-2a62f0c64b4b/datasets/8f267706-24b2-47fb-84ee-3ea3cfc5a0c0\n",
      "[------------------------------------------------->] 7/7"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Experiment Results:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback.answer_correctness</th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>960bed4f-21e3-43b1-9498-dbbb98bb6781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.499785</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.238861</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.132672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242346</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.218822</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.958083</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.496140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.996293</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.539284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.353536</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.567302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.447945</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.613509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.471933</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feedback.answer_correctness error  execution_time  \\\n",
       "count                      7.000000     0        7.000000   \n",
       "unique                          NaN     0             NaN   \n",
       "top                             NaN   NaN             NaN   \n",
       "freq                            NaN   NaN             NaN   \n",
       "mean                       0.499785   NaN        1.238861   \n",
       "std                        0.132672   NaN        0.242346   \n",
       "min                        0.218822   NaN        0.958083   \n",
       "25%                        0.496140   NaN        0.996293   \n",
       "50%                        0.539284   NaN        1.353536   \n",
       "75%                        0.567302   NaN        1.447945   \n",
       "max                        0.613509   NaN        1.471933   \n",
       "\n",
       "                                      run_id  \n",
       "count                                      7  \n",
       "unique                                     7  \n",
       "top     960bed4f-21e3-43b1-9498-dbbb98bb6781  \n",
       "freq                                       1  \n",
       "mean                                     NaN  \n",
       "std                                      NaN  \n",
       "min                                      NaN  \n",
       "25%                                      NaN  \n",
       "50%                                      NaN  \n",
       "75%                                      NaN  \n",
       "max                                      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_name = \"basecamp\"\n",
    "# evaluate just llms\n",
    "run = evaluate(\n",
    "    dataset_name=dataset_name, \n",
    "    llm_or_chain_factory=just_llm, \n",
    "    experiment_name=\"just_llm\",\n",
    "    metrics=[answer_correctness],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6620c4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'rag_chain' at:\n",
      "https://smith.langchain.com/o/9bfbddc5-b88e-41e5-92df-2a62f0c64b4b/datasets/8f267706-24b2-47fb-84ee-3ea3cfc5a0c0/compare?selectedSessions=077a232f-e162-4635-82a4-4db28328fa66\n",
      "\n",
      "View all tests for Dataset basecamp at:\n",
      "https://smith.langchain.com/o/9bfbddc5-b88e-41e5-92df-2a62f0c64b4b/datasets/8f267706-24b2-47fb-84ee-3ea3cfc5a0c0\n",
      "[------------------------------------------------->] 7/7"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Experiment Results:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback.answer_correctness</th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7d1019e7-7e9f-4081-b7bb-93c7a02188fb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.623937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.036328</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.093188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.716885</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.493509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.230393</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.557318</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.622856</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.669444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.157579</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.688257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.577293</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.713456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.466026</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feedback.answer_correctness error  execution_time  \\\n",
       "count                      7.000000     0        7.000000   \n",
       "unique                          NaN     0             NaN   \n",
       "top                             NaN   NaN             NaN   \n",
       "freq                            NaN   NaN             NaN   \n",
       "mean                       0.623937   NaN       10.036328   \n",
       "std                        0.093188   NaN       18.716885   \n",
       "min                        0.493509   NaN        2.230393   \n",
       "25%                        0.557318   NaN        2.622856   \n",
       "50%                        0.669444   NaN        3.157579   \n",
       "75%                        0.688257   NaN        3.577293   \n",
       "max                        0.713456   NaN       52.466026   \n",
       "\n",
       "                                      run_id  \n",
       "count                                      7  \n",
       "unique                                     7  \n",
       "top     7d1019e7-7e9f-4081-b7bb-93c7a02188fb  \n",
       "freq                                       1  \n",
       "mean                                     NaN  \n",
       "std                                      NaN  \n",
       "min                                      NaN  \n",
       "25%                                      NaN  \n",
       "50%                                      NaN  \n",
       "75%                                      NaN  \n",
       "max                                      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate rag_chain\n",
    "run = evaluate(\n",
    "    dataset_name=dataset_name,\n",
    "    llm_or_chain_factory=rag_chain, \n",
    "    experiment_name=\"rag_chain\",\n",
    "    metrics=[answer_correctness], \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7327e4-5f05-4b25-9a42-134070b87cce",
   "metadata": {},
   "source": [
    "Now you can check you langsmith dataset dashboard to view and analyise the results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
