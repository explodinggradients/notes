{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore and Build a test dataset with LangSmith\n",
    "\n",
    "In this notebook we are going to explore the [basecamp handbook](https://basecamp.com/handbook) and generate a synthetic testset for it. We will be using the [Synthetic Test Set generation](https://docs.ragas.io/en/stable/getstarted/testset_generation.html) feature of ragas to generate a testset and then use [Langsmith](https://docs.smith.langchain.com/) to review and store the dataset.\n",
    "\n",
    "Lets get started by exploring the basecamp handbook and then generating a testset for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so that changes to the code are automatically reloaded\n",
    "# ignore if not modifying ragas code directly\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mdata/\u001b[0m\n",
      "├── 37signals-is-you.md\n",
      "├── benefits-and-perks.md\n",
      "├── code-of-conduct.md\n",
      "├── faq.md\n",
      "├── getting-started.md\n",
      "├── how-we-work.md\n",
      "├── international-travel-guide.md\n",
      "├── LICENSE.md\n",
      "├── making-a-career.md\n",
      "├── managing-work-devices.md\n",
      "├── moonlighting.md\n",
      "├── our-internal-systems.md\n",
      "├── our-rituals.md\n",
      "├── performance-plans.md\n",
      "├── product-histories.md\n",
      "├── README.md\n",
      "├── stateFMLA.md\n",
      "├── titles-for-data.md\n",
      "├── titles-for-designers.md\n",
      "├── titles-for-ops.md\n",
      "├── titles-for-programmers.md\n",
      "├── titles-for-support.md\n",
      "├── vocabulary.md\n",
      "├── what-influenced-us.md\n",
      "├── what-we-stand-for.md\n",
      "└── where-we-work.md\n",
      "\n",
      "0 directories, 26 files\n"
     ]
    }
   ],
   "source": [
    "!tree data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthetic Test Set\n",
    "\n",
    "Using Langsmith and Ragas, we outline a straightforward workflow to generate your initial dataset. This dataset can then be utilized to systematically measure and enhance the RAG pipeline's performance. The steps are as follows:\n",
    "1. Load the data as documents. ⏳\n",
    "2. Generate the test set from these documents. ⏳\n",
    "3. Upload and verify the test set with Langsmith. ⏳\n",
    "4. Formulate experiments to improve you RAG pipeline. ⏳\n",
    "5. Choose the right metrics to evaluate the experiment ⏳\n",
    "6. Analyze the results using the Langsmith dashboard. ⏳\n",
    "\n",
    "We'll cover 1 to 3 in this notebook and show you 4 to 6 in the [next one](./baseline-langchain.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data\n",
    "\n",
    "Using langchain document loader we can load the documents from the directory. We loop through the documents to add `file_name` as metadata. This will help Ragas in the testset generation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Load the data as documents\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "loader = DirectoryLoader(\"./data/\")\n",
    "documents = loader.load()\n",
    "\n",
    "# add filename as metadata\n",
    "for document in documents:\n",
    "    document.metadata['file_name'] = document.metadata['source']\n",
    "\n",
    "docs = documents\n",
    "# how many docs do we have\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate the testset\n",
    "\n",
    "Ragas has the Synthetic Test Set generation module to help you create an initial dataset. You can read more about the internals and how it works [here](https://docs.ragas.io/en/latest/concepts/testset_generation.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf223f49807441c934815a38ec22e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes:   0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filename and doc_id are the same for all nodes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "151512368d07400588bb48bdbccd697e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. Generate the testset\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "\n",
    "# generator with openai models\n",
    "generator = TestsetGenerator.with_openai()\n",
    "\n",
    "# generate testset\n",
    "testset = generator.generate_with_langchain_docs(\n",
    "    documents, \n",
    "    test_size=50, \n",
    "\n",
    "    # we can specify the distribution of the different types of questions\n",
    "    distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can view it as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the importance of levelheadedness in t...</td>\n",
       "      <td>[What We Stand For\\n\\nValues\\n\\nBefore anythin...</td>\n",
       "      <td>Levelheadedness is important in the company's ...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does 37signals track and recognize career ...</td>\n",
       "      <td>[Making A Career\\n\\nYour First 90 Days\\n\\nCong...</td>\n",
       "      <td>37signals tracks and recognizes career progres...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the significance of limiting the work ...</td>\n",
       "      <td>[als better.\\n\\nAs soon as organizational bott...</td>\n",
       "      <td>Limiting the work week to 40 hours helps prior...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What options are available for working remotel...</td>\n",
       "      <td>[Where We Work\\n\\nFrom home\\n\\nMost people at ...</td>\n",
       "      <td>Working from coffee shops or other third space...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What types of bugs do you fix for your legacy ...</td>\n",
       "      <td>[Frequently Asked Questions\\n\\nWhere should I ...</td>\n",
       "      <td>We do fix any security or privacy related bugs...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the importance of levelheadedness in t...   \n",
       "1  How does 37signals track and recognize career ...   \n",
       "2  What is the significance of limiting the work ...   \n",
       "3  What options are available for working remotel...   \n",
       "4  What types of bugs do you fix for your legacy ...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [What We Stand For\\n\\nValues\\n\\nBefore anythin...   \n",
       "1  [Making A Career\\n\\nYour First 90 Days\\n\\nCong...   \n",
       "2  [als better.\\n\\nAs soon as organizational bott...   \n",
       "3  [Where We Work\\n\\nFrom home\\n\\nMost people at ...   \n",
       "4  [Frequently Asked Questions\\n\\nWhere should I ...   \n",
       "\n",
       "                                        ground_truth evolution_type  \\\n",
       "0  Levelheadedness is important in the company's ...         simple   \n",
       "1  37signals tracks and recognizes career progres...         simple   \n",
       "2  Limiting the work week to 40 hours helps prior...         simple   \n",
       "3  Working from coffee shops or other third space...         simple   \n",
       "4  We do fix any security or privacy related bugs...         simple   \n",
       "\n",
       "   episode_done  \n",
       "0          True  \n",
       "1          True  \n",
       "2          True  \n",
       "3          True  \n",
       "4          True  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = testset.to_pandas()\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Upload and verify the testset with Langsmith\n",
    "\n",
    "The synthetic dataset need to be manually reviewed to ensure that is matches the kinds of questions your users might ask. This is a point in this workflow that needs human feedback. We are working on algorithms and techniques to minimize it but for now it is a necessary step.\n",
    "\n",
    "Langsmith is a great tool to review and store your datasets. It has a simple interface to review the dataset and then store it in a way that it can be used for future experiments.\n",
    "\n",
    "You can directly use the ragas integration to upload the dataset to langsmith or check the [docs](https://docs.smith.langchain.com/evaluation/faq/datasets-client) on how to do it with the langsmith client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a new dataset 'basecamp'. Dataset is accessible at https://smith.langchain.com/o/9bfbddc5-b88e-41e5-92df-2a62f0c64b4b/datasets/e9dc7bc8-9d47-4efd-8f4c-678a18a7aef5\n"
     ]
    }
   ],
   "source": [
    "from ragas.integrations.langsmith import upload_dataset\n",
    "\n",
    "dataset_name = \"basecamp\"\n",
    "dataset_desc = \"Synthetic testset data for basecamp\"\n",
    "\n",
    "dataset = upload_dataset(testset, dataset_name, dataset_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets verify it with LangSmith. \n",
    "\n",
    "![langsmith dataset dashboard](./images/dataset_overview.png)\n",
    "\n",
    "What is event better is that langsmith gives you an interface to manually review the dataset which involves:\n",
    "\n",
    "1. Eye-ball each row and see if everything is correct\n",
    "![dataset row view](./images/data_row_view.png)\n",
    "\n",
    "2. If not correct, you can edit the row and then save it or select the row and remove it from the datasets.\n",
    "![edit row view](./images/dataset_row_edit.png)\n",
    "\n",
    "\n",
    "\n",
    "This is a time consuming process but it is necessary to ensure that the dataset is of high quality. If not done the evaluations we do later will not be accurate. Also you are the best judge for your usecase and hence it is important to review the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a test dataset generated and reviewd we can move on to\n",
    "\n",
    "4. Conduct evaluations using Ragas metrics for various experiments.\n",
    "5. Analyze the results using the Langsmith dashboard.\n",
    "\n",
    "Let's explore than in this [notebook](./baseline-langchain.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
