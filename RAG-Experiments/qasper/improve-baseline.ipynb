{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a59eee7-1c57-4fd7-82d9-59d4536e5346",
   "metadata": {},
   "source": [
    "# Improvements we want to try\n",
    "\n",
    "Things we want to try\n",
    "- improve retriever with reranker\n",
    "- improve generation with gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a93288c-b935-47f0-b710-75d937b60526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "\n",
    "# load old baseline\n",
    "def load_index(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        raise FileNotFoundError(\"Saved index not found!\")\n",
    "        \n",
    "    # load the existing index\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=dir)\n",
    "    index = load_index_from_storage(storage_context)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "541b5f2a-9bb1-420d-896c-ac903e31b7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_index = load_index(\"./rags/baseline/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d508a1a6-cd26-441c-8f4c-46556d49e3ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are some linguistic signals of dogmatic l...</td>\n",
       "      <td>['ers, often in a strongly opinionated way (“y...</td>\n",
       "      <td>Present tense, past tense, negative emotion, s...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does the previous vowel affect the pronunc...</td>\n",
       "      <td>[' ein English that affects the pro-\\nnunciati...</td>\n",
       "      <td>The previous vowel affects the pronunciation o...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the two natural language processing t...</td>\n",
       "      <td>['arXiv:1909.09067v1  [cs.CL]  19 Sep 2019A Co...</td>\n",
       "      <td>The two natural language processing tasks that...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the Cloze objective of MLM in cross-li...</td>\n",
       "      <td>['Figure 2: The overview of BRidge Language Mo...</td>\n",
       "      <td>The Cloze objective of MLM in cross-lingual pr...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  ... episode_done\n",
       "0  What are some linguistic signals of dogmatic l...  ...         True\n",
       "1  How does the previous vowel affect the pronunc...  ...         True\n",
       "2  What are the two natural language processing t...  ...         True\n",
       "3  What is the Cloze objective of MLM in cross-li...  ...         True\n",
       "\n",
       "[4 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load testset\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./valid_first_10_ragas.csv\", index_col=0)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# select a subset\n",
    "df = df.iloc[:4]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c9e213-45c7-4dcc-9db3-ed3fd17e0576",
   "metadata": {},
   "source": [
    "# Improve Retreiver\n",
    "\n",
    "lets use Cohere reranker module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86c99e8e-be78-4c96-874c-04078cbab56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.postprocessor.cohere_rerank import CohereRerank\n",
    "\n",
    "\n",
    "api_key = os.environ[\"COHERE_API_KEY\"]\n",
    "cohere_rerank = CohereRerank(api_key=api_key, top_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "69cdaeab-42a1-498a-bf5c-1606af223810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the two natural language processing tasks that deal with the concept of simplified language?\n"
     ]
    }
   ],
   "source": [
    "i = 2\n",
    "print(f\"{df.question[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "437fd5e3-d5ab-42f4-96e9-64281ef07d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic readability assessment and automatic text simplification.\n",
      "Node ID: ee6895fb-9704-4772-873a-3a3be7515948\n",
      "Text: arXiv:1909.09067v1  [cs.CL]  19 Sep 2019A Corpus for Automatic\n",
      "Readability Assessment and Text Simp liﬁcation of German Alessia\n",
      "Battisti Institute of Computational Linguistics University of Zurich\n",
      "Andreasstrasse 15, 8050 Zurich alessia.battisti@uzh.chSarah Ebling\n",
      "Institute of Computational Linguistics University of Zurich\n",
      "Andreasstrasse 15, 8050...\n",
      "Score:  0.999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# improved\n",
    "query_engine_cohere = baseline_index.as_query_engine(\n",
    "    similarity_top_k=10,\n",
    "    node_postprocessors=[cohere_rerank],\n",
    ")\n",
    "improved_ret = query_engine_cohere.retrieve\n",
    "\n",
    "resp = query_engine_cohere.query(df.question[i])\n",
    "print(resp)\n",
    "print(resp.source_nodes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d8ddeb7c-9d86-4cc6-a55a-ffa03ecb8c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic text simplification and readability assessment.\n",
      "Node ID: 959781a9-7849-4b2a-b213-89f25189a72a\n",
      "Text: From a behavioral standpoint, dogmatic people solve problems\n",
      "differently, spend- ing less time framing a problem and expressing\n",
      "more certainty in their solution (Lohman, 2010). Here we similarly\n",
      "examine how user behaviors on Reddit re- late to a language model of\n",
      "dogmatism. Ertel sought to capture dogmatism linguistically, though a\n",
      "small lexicon...\n",
      "Score:  0.871\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# baseline\n",
    "query_engine_baseline = baseline_index.as_query_engine()\n",
    "baseline_ret = baseline_index.as_retriever()\n",
    "\n",
    "resp = query_engine_baseline.query(df.question[i])\n",
    "print(resp)\n",
    "nodes = baseline_ret.retrieve(df.question[0])\n",
    "print(nodes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5e3ea8-54e1-4e6e-b076-313cc8d88b63",
   "metadata": {},
   "source": [
    "## Check a few Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8aad80ab-1ce4-436b-b736-e9acdb5b77e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import context_precision, context_recall\n",
    "from ragas import evaluate\n",
    "\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "faf61f64-effc-4c74-959f-64d1fc308c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "\n",
    "q = df.question[i]\n",
    "gt = df.ground_truth[i]\n",
    "\n",
    "baseline_response = query_engine_baseline.query(q)\n",
    "improved_response = query_engine_cohere.query(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b05956f1-ea13-43ef-ad5d-89de32b6789f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate single\n",
    "row = {\n",
    "    \"question\": [q],\n",
    "    \"ground_truth\": [gt],\n",
    "    \"baseline_contexts\": [[n.node.text for n in baseline_response.source_nodes]],\n",
    "    \"improved_contexts\": [[n.node.text for n in improved_response.source_nodes]],\n",
    "}\n",
    "ds = Dataset.from_dict(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2316eb87-662c-4ecc-8419-3d2f5b699b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attaching a tracer\n",
    "# langsmith\n",
    "from langchain.callbacks.tracers import LangChainTracer\n",
    "\n",
    "tracer = LangChainTracer(project_name=\"notes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2971761e-f2bf-4800-955f-810602de5f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2929ddd2c0541528b6cdb90e72df328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'context_precision': 1.0000, 'context_recall': 1.0000}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline\n",
    "r = evaluate(\n",
    "    ds, \n",
    "    metrics=[context_precision, context_recall], column_map={\"contexts\": \"baseline_contexts\"},\n",
    "    callbacks=[tracer],\n",
    ")\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64aad025-c83c-418b-a272-fa12f09dd61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eb51adc5fe4456b857d4eca32b859e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'context_precision': 1.0000, 'context_recall': 1.0000}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline\n",
    "r = evaluate(\n",
    "    ds, \n",
    "    metrics=[context_precision, context_recall], column_map={\"contexts\": \"improved_contexts\"},\n",
    "    callbacks=[tracer],\n",
    ")\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0740c99d-29d7-4c50-baef-4efc6d0a8481",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "122cb6a8-2567-471f-b4e7-9b9189785070",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  4.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# build dataset - baseline\n",
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "baseline_contexts = []\n",
    "for q in tqdm(df.question):\n",
    "    resp = await query_engine_baseline.aretrieve(q)\n",
    "    baseline_contexts.append(\n",
    "        [n.node.text for n in resp]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d5b85e34-1837-4d4d-9880-cceaf21c3c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 4/4 [00:06<00:00,  1.60s/it]\n"
     ]
    }
   ],
   "source": [
    "# build dataset - improved\n",
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "improved_contexts = []\n",
    "\n",
    "for q in tqdm(df.question):\n",
    "    resp = await query_engine_cohere.aquery(q)\n",
    "    improved_contexts.append(\n",
    "        [n.node.text for n in resp.source_nodes]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e8c13747-b43d-470d-8a70-927e24d6d782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dataset\n",
    "dataset_dict = {\n",
    "    \"question\": df.question,\n",
    "    \"baseline_contexts\": baseline_contexts,\n",
    "    \"improved_contexts\": improved_contexts,\n",
    "    \"ground_truth\": df.ground_truth\n",
    "}\n",
    "\n",
    "ds = Dataset.from_dict(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a704501c-98f7-4c5a-8141-3fe67fd68957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6600a922ad3443ffab98bec6cff2d374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'context_precision': 0.8750, 'context_recall': 1.0000}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate baseline\n",
    "rag_eval_result = evaluate(\n",
    "    ds, \n",
    "    metrics=[context_precision, context_recall], \n",
    "    column_map={\"contexts\": \"baseline_contexts\"},\n",
    "    callbacks=[tracer],\n",
    "    raise_exceptions=False,\n",
    ")\n",
    "rag_eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "38813ff7-4015-47a5-ba4f-552dbe34bce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e194c2f46810402695d3d9cee321c3f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'context_precision': 1.0000, 'context_recall': 1.0000}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate improved\n",
    "rag_eval_result = evaluate(\n",
    "    ds, \n",
    "    metrics=[context_precision, context_recall], \n",
    "    column_map={\"contexts\": \"improved_contexts\"},\n",
    "    callbacks=[tracer],\n",
    "    raise_exceptions=False,\n",
    ")\n",
    "rag_eval_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d1440b-2bdc-4c13-bf7f-df5c7bc56ea8",
   "metadata": {},
   "source": [
    "# Improve LLM\n",
    "\n",
    "lets try GPT-4 RAG with `faithfulness` and `answer_correctness`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "33e941fd-37fa-44f1-9e74-337c37521ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "gpt4 = OpenAI(model=\"gpt-4\")\n",
    "\n",
    "# Local settings\n",
    "qe_gpt4 = baseline_index.as_query_engine(llm=gpt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "09eff0c5-e1fc-47b2-826a-d305eaeb6d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 4/4 [00:17<00:00,  4.44s/it]\n"
     ]
    }
   ],
   "source": [
    "# build dataset - gpt4-rag\n",
    "\n",
    "improved_answer = []\n",
    "improved_contexts = []\n",
    "\n",
    "for q in tqdm(df.question.iloc[:4]):\n",
    "    resp = await qe_gpt4.aquery(q)\n",
    "    improved_answer.append(resp.response)\n",
    "    improved_contexts.append(\n",
    "        [n.node.text for n in resp.source_nodes]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2f8c117b-499a-43f7-bce8-b31306f80f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.23s/it]\n"
     ]
    }
   ],
   "source": [
    "# build dataset - baseline-rag\n",
    "\n",
    "rag_contexts = []\n",
    "rag_answer = []\n",
    "for q in tqdm(df.question.iloc[:4]):\n",
    "    resp = await query_engine_baseline.aquery(q)\n",
    "    rag_answer.append(resp.response)\n",
    "    rag_contexts.append(\n",
    "        [n.node.text for n in resp.source_nodes]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "86f09fae-be9b-4d96-8fe5-9e64ee4ec803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dataset\n",
    "dataset_dict = {\n",
    "    \"question\": df.question,\n",
    "    \"baseline_answer\": rag_answer,\n",
    "    \"baseline_contexts\": rag_contexts,\n",
    "    \"gpt4_answer\": improved_answer,\n",
    "    \"gpt4_contexts\": improved_contexts,\n",
    "    \"ground_truth\": df.ground_truth\n",
    "}\n",
    "\n",
    "ds = Dataset.from_dict(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1ddbaab4-c237-4e90-968c-c4bac7954345",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import answer_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "63876f20-3a25-4e78-b548-8e934d4a36ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8128a3dd239e47268d0a9b10bcce4264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 0.8393, 'answer_correctness': 0.7185, 'answer_similarity': 0.9632}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate baseline\n",
    "rag_eval_result = evaluate(\n",
    "    ds, \n",
    "    metrics=[faithfulness, answer_correctness, answer_similarity], \n",
    "    column_map={\"contexts\": \"baseline_contexts\", \"answer\": \"baseline_answer\"},\n",
    "    callbacks=[tracer],\n",
    "    raise_exceptions=False,\n",
    ")\n",
    "rag_eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a8c80535-b748-4e9f-afc3-56f98ea2b1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a3757f8fe184033bf2cdfae443b335c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 0.8750, 'answer_correctness': 0.6627, 'answer_similarity': 0.9465}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate gpt4\n",
    "rag_eval_result = evaluate(\n",
    "    ds, \n",
    "    metrics=[faithfulness, answer_correctness, answer_similarity], \n",
    "    column_map={\"contexts\": \"gpt4_contexts\", \"answer\": \"gpt4_answer\"},\n",
    "    callbacks=[tracer],\n",
    "    raise_exceptions=False,\n",
    ")\n",
    "rag_eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "100dd524-3355-4986-95f4-05b06e81e8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_correctness.weights = [1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "812f27be-0db7-4382-ad4e-24b31ece3c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d7a6021bda44ce1baa6f05ca39b6858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 0.8750, 'answer_correctness': 0.5431, 'answer_similarity': 0.9465}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate gpt4\n",
    "rag_eval_result = evaluate(\n",
    "    ds, \n",
    "    metrics=[faithfulness, answer_correctness, answer_similarity], \n",
    "    column_map={\"contexts\": \"gpt4_contexts\", \"answer\": \"gpt4_answer\"},\n",
    "    callbacks=[tracer],\n",
    "    raise_exceptions=False,\n",
    ")\n",
    "rag_eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2e0e8d99-495b-4c54-a123-c01128af5b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>baseline_answer</th>\n",
       "      <th>baseline_contexts</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_correctness</th>\n",
       "      <th>answer_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are some linguistic signals of dogmatic l...</td>\n",
       "      <td>Pronouns, verb tense, sentiment (positive or n...</td>\n",
       "      <td>[From a behavioral standpoint,\\ndogmatic peopl...</td>\n",
       "      <td>Linguistic signals of dogmatic language includ...</td>\n",
       "      <td>[From a behavioral standpoint,\\ndogmatic peopl...</td>\n",
       "      <td>Present tense, past tense, negative emotion, s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.949174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does the previous vowel affect the pronunc...</td>\n",
       "      <td>The pronunciation of words in English can be a...</td>\n",
       "      <td>[But despite\\nbeing glottographic, in few writ...</td>\n",
       "      <td>In English, the pronunciation of a vowel can b...</td>\n",
       "      <td>[But despite\\nbeing glottographic, in few writ...</td>\n",
       "      <td>The previous vowel affects the pronunciation o...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.890755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the two natural language processing t...</td>\n",
       "      <td>Text simplification and readability assessment...</td>\n",
       "      <td>[As\\npart of a rule-based approach, the operat...</td>\n",
       "      <td>The two natural language processing tasks that...</td>\n",
       "      <td>[As\\npart of a rule-based approach, the operat...</td>\n",
       "      <td>The two natural language processing tasks that...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.984958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the Cloze objective of MLM in cross-li...</td>\n",
       "      <td>The Cloze objective of MLM in cross-lingual pr...</td>\n",
       "      <td>[In the pretraining phase, we ﬁrst pretrain ML...</td>\n",
       "      <td>The Cloze objective of Masked Language Modelin...</td>\n",
       "      <td>[In the pretraining phase, we ﬁrst pretrain ML...</td>\n",
       "      <td>The Cloze objective of MLM in cross-lingual pr...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.961062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  ... answer_similarity\n",
       "0  What are some linguistic signals of dogmatic l...  ...          0.949174\n",
       "1  How does the previous vowel affect the pronunc...  ...          0.890755\n",
       "2  What are the two natural language processing t...  ...          0.984958\n",
       "3  What is the Cloze objective of MLM in cross-li...  ...          0.961062\n",
       "\n",
       "[4 rows x 9 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df = rag_eval_result.to_pandas()\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed112fe2-dc9c-4609-a976-df5739117ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
