---
title: Using Kibana
description: "Information on what Kibana is, how to search it, interpret its results, and tips and tricks for getting specific information from it."
category: Infrastructure for troubleshooting
---

### Overview

This document provides information on what Kibana is, how to search it, interpret its results, and contains tips and tricks on getting specific information from it.

### Using Kibana

[Kibana](https://log.gprd.gitlab.net/) is an [open source data visualization plugin](https://www.elastic.co/kibana) for [Elasticsearch](https://en.wikipedia.org/wiki/Elasticsearch). It provides visualization capabilities on top of the content indexed on an Elasticsearch cluster. Support Engineering uses Kibana to both search for error events on GitLab.com and to detect when specific changes were made to various aspects of it by a user.

>**Note:** Kibana does not retain logs older than 7 days.

#### Parameters

Knowing *where* to search in Kibana is paramount to getting the proper results. The area of the application (GitLab.com) that you're searching is known as the `Index` in Kibana. The default index used for searching is `pubsub-rails-inf-gprd-*` but you can change this by clicking the `(change)` button:

![Changing search index](/images/support/kibana_index-selection.jpg)

Indexes closely correlate for the most part with our [log structure](https://docs.gitlab.com/ee/administration/logs.html) in general. Some other frequently used indexes are:

- `pubsub-gitaly-inf-gprd-*`
- `pubsub-pages-inf-gprd-*`
- `pubsub-runner-inf-gprd-*`

For example, if you're trying to track down failed logins you would search the index `pubsub-rails-inf-gprd-*`. To search for [`500` errors](/handbook/support/workflows/500_errors.html) involving a controller you'd search in `pubsub-rails-inf-gprd-*`, the default index.

Along with the index, knowing *when* a specific error or event ocurred that you're trying to track down  is important and it's important to keep in mind that Kibana logs on GitLab.com persist for seven days. Kibana allows you to choose relative and absolute time ranges for search results and this can be changed by manipulating the date range:

![Changing the date range](/images/support/kibana_changing-dates.jpg)

#### Fields and Filters

**Note:** As of March 2022, using `Filters` is the recommended way for searching Kibana. Using the general search box is discouraged as it may generate several errors in the form of `X of Y Shards Failed`. See [Infra Issue](https://gitlab.com/gitlab-com/gl-infra/reliability/-/issues/15207).

Each log entry is comprised of a number of `Fields` in which the specific information about the entry is displayed. Knowing which fields to apply to your search results and how to filter for them is just as important as knowing *where* and *when* to search. The most important fields are:

- `json.method`
- `json.action`
- `json.controller` - for more on this see the [controller definitions in the GitLab sourcecode](https://gitlab.com/gitlab-org/gitlab/-/tree/master/app/controllers/projects)
- `json.status`
- `json.path`

All available fields are displayed along the left-hand side menu and you can add them to your search results by hovering over each and clicking the `add` button.

![Viewing the list of fields](/images/support/kibana_available-fields.jpg)

If you don't filter for specific fields it can be difficult to find specific log entries if a large number of them are returned on your search query.

For example, we're trying to locate any log events generated by the GitLab.com user `tristan` that returned a `404` status code within the last 15 minutes. We can start by searching the `pubsub-rails-inf-gprd-*` index for `json.username : tristan` within that time range and we'd get results similar to the following once we click `add` next to the `json.status` field along the left-hand side bar:

![Unfiltered results for a specific username](/images/support/kibana_unfiltered-results.jpg)

The majority of results as entries that returned `200`, which aren't in the scope of what we're looking for. To search for results where `404` was returned we can click `+ Add Filter` underneath the search bar and place a positive filter on `json.status is 404`, which will give us these results, exactly what we're looking for.

![Filtered results for a specific username](/images/support/kibana_filtered-results.jpg)

#### Identify cause of IP Blocks

There are some useful tips [here]({{< ref "ip-blocks" >}}) about searching kibana for errors related to IP blocks.

#### Log Identification

Not sure what to look for? Consider using a Self-Managed instance to replicate the bug/action you're investigating. This will allow you to confirm whether or not an issue is specific to GitLab.com, while also providing easily accessible logs to reference while searching through Kibana.

Support Engineers looking to configure a Self-Managed instance should review our [Sandbox Cloud page](/handbook/infrastructure-standards/realms/sandbox/) for a list of available (company provided) hosting options.

### Tips and Tricks

This section details how you can find very specific pieces of information in Kibana by searching for and filtering out specific fields. Each tip includes a link to the group, subgroup, or project that was used in the example for reference.

#### Runner Registration Token Reset

Example group: [gitlab-bronze](https://gitlab.com/gitlab-bronze)

We can determine if the GitLab Runner registration token was reset for a group or project and see which user reset it and when. For this example the Runner registration token was reset at the group-level in `gitlab-bronze`. To find the log entry:

1. Set the date range to a value that you believe will contain the result. Set it to `Last 7 days` if you're unsure.
1. Add a positive filter on `json.path` for the path of the group, which is just `gitlab-bronze` in this example.
1. Add a positive filter on `json.action` for `reset_registration_token`.
1. Observe the results. If there were any they will contain the username of the user that triggered the reset in the `json.username` field of the result.

#### Deleted Group/Subgroup/Project

- Example group: [gitlab-silver](https://gitlab.com/gitlab-silver/)
- Example project: [gitlab-silver/test-project-to-delete](https://gitlab.com/gitlab-silver/test-project-to-delete)

Kibana can be used to determine who triggered the deletion of a group, subgroup, or project on GitLab.com. To find the log entry:

1. In `pubsub-rails-inf-gprd-*`, set the date range to a value that you believe will contain the result. Set it to `Last 7 days` if you're unsure.
1. Add a positive filter on `json.path` for the path of the project, including the group and subgroup, if applicable. This is `gitlab-silver/test-project-to-delete` in this example.
1. Add a positive filter on `json.method` for `DELETE`.
1. Observe the results. If there were any they will contain the username of the user that triggered the deletion in the `json.username` field of the result.
When a project or a group is first going to pending deletion the log entry will have `json.params.key: [_method, authenticity_token, namespace_id, id]`, compare to when a user is [forcing the deletion](https://docs.gitlab.com/ee/user/project/settings/index.html#delete-a-project-immediately) then the log entry looks like `json.params.key: [_method, authenticity_token, permanently_delete, namespace_id, id]` for project or looks like `json.params.key: [_method, authenticity_token, permanently_remove, id]` for group.

To see a list of projects deleted as part of a (sub)group deletion, in sidekiq:

1. Filter `json.message` to "was deleted".
1. Set a second filter `json.message` to `path/group`.

#### Viewed CI/CD Variables

While we do not specifically log *changes* made to CI/CD variables in our [audit logs for group events](https://docs.gitlab.com/ee/administration/audit_events.html#group-events), there is a way to use Kibana to see who may have viewed the variables page. Viewing the variables page is required to change the variables in question. While this does *not* necessarily indicate someone who has viewed the page in question has made changes to the variables, it should help to narrow down the list of potential users who could have done so. (If you'd like us to log these changes, we have [an issue open here to collect your comments](https://gitlab.com/gitlab-org/gitlab/-/issues/8070).)

1. Set a filter for `json.path` `is` and then enter the full path of the associated project in question, followed by `/-/variables`. For example, if I had a project named `tanuki-rules`, I would enter `tanuki-rules/-/variables`.
1. Set the date in Kibana to the range in which you believe a change was made.
1. You should be able to then view anyone accessing that page within that time frame. The `json.meta.user` should show the user's username and the `json.time` should show the timestamp during which the page was accessed.
1. You may also be able to search by `json.graphql.operation_name` `is` `getProjectVariables`.
1. In general, a result in the `json.action` field that returns `update` and `json.controller` returning `Projects::VariablesController` is likely to mean that an update was done to the variables.

#### Find Problems with Let's Encrypt Certificates

In some cases a Let's Encrypt Certificate will fail to be issued for one or more reasons. To determine the exact reason, we can look this up in Kibana.

1. Set a positive filter for `json.message` to "Failed to obtain Let's Encrypt certificate".
1. In the search bar, enter in the GitLab Pages domain name. For example `json.pages_domain: "sll-error.shushlin.dev"`
1. Filter by or find `json.acme_error.detail` This should display the relevant error message. In this case, we can see the error "No valid IP addresses found for sll-error.shushlin.dev"

#### Deleted User

Kibana can be used to find out if and when an account on GitLab.com was deleted if it occurred within the last seven days at the time of searching.

- Set the date range to a value that you believe will contain the result. Set it to `Last 7 days` if you're unsure.

If an account was self-deleted, try searching with these filters:

1. Add a positive filter on `json.username` for the username of the user, if you have it.
1. Add a positive filter on `json.controller` for `RegistrationsController`.

If an account was deleted by an admin, try searching with these filters:

1. Add a positive filter on `json.params.value` for the username of the user.
1. Add a positive filter on `json.method` for `DELETE`.

Observe the results. There should be only one result if the account that was filtered for was deleted within the specified timeframe.

#### Disable Two Factor Authentication

- [Quick link to search](https://log.gprd.gitlab.net/goto/5598ea40-a651-11ed-9f43-e3784d7fe3ca)

Kibana can be used to find out which admin disabled 2FA on a GitLab.com account. To see the log entries:

1. Set the date range to a value that you believe will contain the result. Set it to `Last 7 days` if you're unsure.
1. Add a positive filter on `json.location` for the `username` 2FA was disabled for.
1. Add a positive filter on `json.action` for `disable_two_factor`.
1. To make things easier to read, only display the `json.location` and `json.username` fields.
1. Observe the results.

#### Enable/Disable SSO Enforcement

Kibana can be used to find out if and when SSO Enforcement was enabled or disabled on a group on GitLab.com, and which user did so.

- Example group: [gitlab-silver](https://gitlab.com/gitlab-silver/)

##### Enable SSO Enforcement

1. Set the date range to a value that you believe will contain the result. Set it to `Last 7 days` if you're unsure.
1. Add a positive filter on `json.controller` for `Groups::SamlProvidersController`.
1. Add a positive filter on `json.action` for `update`.
1. Add a positive filter on `json.method` for `PATCH`.
1. Add a positive filter on `json.path` for the path of the group, `gitlab-silver` in this example case.
1. If there are any results, observe the `json.params` field. If `\"enforced_sso\"=>\"1\"` is present, that entry was logged when SSO Enforcement was enabled by the user in the `json.username` field.

##### Disable SSO Enforcement

1. Set the date range to a value that you believe will contain the result. Set it to `Last 7 days` if you're unsure.
1. Add a positive filter on `json.controller` for `Groups::SamlProvidersController`.
1. Add a positive filter on `json.action` for `update`.
1. Add a positive filter on `json.method` for `PATCH`.
1. Add a positive filter on `json.path` for the path of the group, `gitlab-silver` in this example case.
1. If there are any results, observe the `json.params` field. If `\"enforced_sso\"=>\"0\"` is present, that entry was logged when SSO Enforcement was disabled by the user in the `json.username` field.

##### SAML log in

To investigate SAML login problems:

In the `pubsub-rails-inf-gprd-*` log:

1. Set the date range to a value that you believe will contain the result. Set it to `Last 7 days` if you're unsure.
1. Add a positive filter as advised in [our SAML groups docs](https://docs.gitlab.com/ee/user/group/saml_sso/troubleshooting.html#searching-rails-log-for-a-saml-response).

After decoding the SAML response, and observing the results corresponding to your chosen filters, you can see if there are any missing or misconfigured attributes.

#### Searching for Deleted Container Registry tags

Kibana can be used to determine whether a container registry tag was deleted, when, and who triggered it, if the deletion happened in the last 7 days.

To find the log entry in `pubsub-rails-inf-gprd-*`:

1. Get the link for the container registry in question. (For exmaple: <https://gitlab.example.com/group/project/container_registry/><ContainerRepository>)
1. Set the date range to a value that you believe will contain the result. Set it to `Last 7 days` if you're unsure.
1. Add a positive filter on `json.graphql.variables` for `*ContainerRepository/<regitsry id>.*`.
1. Add a positive filter on `json.graphql.operation_name` for `destroyContainerRepositoryTags`.

#### Searching Kibana for 500 level errors

As of [14.7, a Correlation ID is provided](https://gitlab.com/gitlab-org/gitlab/-/issues/34113) on the 500 error page when using the interface. You can ask the customer to supply this and use Kibana to filter by `json.correlation_id`.

Kibana is not typically used to locate `5XX` errors, but there are times where they can't be easily found in Sentry and searching Kibana first is beneficial. To perform a general search in Kibana:

1. Obtain the full URL the user was visiting when the error occurred.
1. [Log in to Kibana](https://log.gitlab.net/app/kibana#).
1. Select the correct time filter (top right) - e.g last 30 minutes, 24 hours, or 7 days.
1. Use the search field to narrow down the results. For example you can search the `gitlab-ee` project for any mention of `error` using the following query:

```plaintext
"gitlab-ee" AND "error"
```

It's recommended to apply a **Negative Filter** to the `gitlab_error.log` and `gitlab_access.log` log files. These two generate a large amount of noise and may not be relevant to your search.

See the [500 errors workflow]({{< ref "500_errors" >}}) for more information on searching and finding errors on GitLab.com

#### Filter by IP Range

Customers will sometimes give us an IP Range of their resources such as their Kubernetes cluster or other external servers that may need to access GitLab. You can search a range by using Elasticsearch Query DSL.

1. Click `+ Add Filter` > `Edit as Query DSL`
1. Use the following format to create your query:

```json
{
  "query": {
    "term": {
      "json.remote_ip": {
        "value": "192.168.0.1/20"
      }
    }
  }
}
```

1. Click Save to perform your query.

Note that depending on the range, this operation may be expensive so it is best to first narrow down your date range first.

#### Import Errors

Most timeout related imports end up with a partial import with very few or zero issues or merge requests. Where there is a relatively smaller difference (10% or less), then there are most likely errors with those specific issues or merge requests.

Anytime there is an error, ensure that the export originated from a [compatible version of GitLab](https://docs.gitlab.com/ee/user/project/settings/import_export.html#version-history).

Here are some tips for searching for import errors in Kibana:

- Use the pubsub-sidekiq-inf-gprd index pattern (Sidekiq logs) and try to narrow it down by adding filters
  - json.meta.project: `path/to/project`
  - json.severity: (not `INFO`)
  - json.job_status: (not `done`)
  - json.class is `RepositoryImportWorker`
- Use the pubsub-rails-inf-gprd index pattern (Rails logs) and try to narrow it down by adding filters
  - json.controller: `Projects::ImportsController` with error status
  - json.path: `path/to/project`
- In Sentry, search/look for: `Projects::ImportService::Error` ; make sure to remove the `is:unresolved` filter.

If there is an error, search for an existing issue. Errors where the metadata is throwing an error and no issue exists, consider creating one from Sentry.

If no error is found and the import is partial, most likely it is a timeout issue.

##### Known Import Issues

- **Imported project's size differs from where it originated**
  - See [this comment](https://gitlab.com/gitlab-org/gitlab/-/issues/27742#note_215721494) for an explanation as to why. As artifacts are part of repository size, whether they are present can make a big difference.
- **Repository shows 0 commits**.
  - See [15348](https://gitlab.com/gitlab-org/gitlab/issues/15348).

#### Correlation Dashboard

If you found a Correlation ID that is relevant for your troubleshooting, you can utilize the correlation dashboard to quickly view all related components across indices without having to search each individual index. You can get to the correlation dashboard by navigating to `Analytics > Dashboard` in Kibana and typing in `correlation dashboard`. Once you view the dashboard, simply click on the `json.correlation_id` filter and enter in your found correlation ID. It will then search across web, workhorse, sidekiq, and gitaly indices.

#### Purchase Errors

Kibana can be used to search for specific errors related to a purchase attempt. Since purchases can be made either in GitLab.com or [CustomersDot](https://customers.gitlab.com/customers/sign_in), it is important to determine which system a customer was using to make the purchase; then use the tips specific to the system below. **Note:** the ticket submitter might not be the customer making the purchase.

##### GitLab.com purchase errors

**Note**: You need to have the **GitLab username** of the account used to make the purchase. Sometimes the user fills the `GitLab username` value of the ticket fields, or you can check the ticket requester's GitLab username in the [GitLab User Lookup Zendesk App](https://handbook.gitlab.com/handbook/support/readiness/operations/docs/zendesk/apps/#gitlab-super-app).

1. Navigate to [Kibana](https://log.gprd.gitlab.net/)
1. Ensure the `pubsub-rails-inf-gprd-*` index pattern (GitLab.com logs) is selected.
1. Set the date range to a value that you believe will contain the result. Set it to `Last 7 days` if you're unsure.
1. Add a positive filter on `json.user.username` for the username of the account used to make the purchase.
1. Add a positive filter on `json.tags.feature_category` for `purchase`.

Feeling Lazy? Go to `https://log.gprd.gitlab.net/goto/6aac4580-9d9b-11ed-85ed-e7557b0a598c` and update the value of `json.user.username`.

If you encounter a generic error message try checking CustomersDot purchase error logs in [Kibana](#customersdot-purchase-errors) or [GCP](/handbook/support/license-and-renewals/workflows/customersdot/troubleshoot_errors_while_making_purchases.html#getting-error-messages-from-gcp-logs-explorer) for a more specific error.

**Tip:** To see the details of a user's purchase attempt, go to `https://log.gprd.gitlab.net/goto/45bb89c0-6ccc-11ed-9f43-e3784d7fe3ca` and update the value of `json.username`.

##### CustomersDot purchase errors

**Note**: You need to have the **CustomersDot customer ID** of the account used to make the purchase. Refer to `Step 1` under [this section](/handbook/support/license-and-renewals/workflows/customersdot/troubleshoot_errors_while_making_purchases.html#getting-error-message-from-sentry) on how to get the customer ID.

1. Navigate to [Kibana](https://log.gprd.gitlab.net/)
1. Ensure the `pubsub-rails-inf-prdsub-*` index pattern (CustomersDot logs) is selected.
1. Set the date range to a value that you believe will contain the result. Set it to `Last 7 days` if you're unsure.
1. Add a positive filter on `json.customer_id` for the username of the account used to make the purchase.
1. Add a positive filter on `json.severity` for `ERROR`.

Feeling Lazy? Go to `https://log.gprd.gitlab.net/goto/9c28ba80-9d9b-11ed-9f43-e3784d7fe3ca` and update the value of `json.customer_id`.

In case you have the namespace details, get the **Namespace ID** then go to `https://log.gprd.gitlab.net/goto/b598dfe0-9d9b-11ed-9f43-e3784d7fe3ca` and update the value of `json.params.gl_namespace_id`

#### Check user actions on a repository

When looking at the `pubsub-rails-inf-gprd-*` index, you can determine if a user has recently cloned, pushed, or downloaded a repository. You can filter by `json.username`, `json.path` (the repository), and `json.action` to find specific events:

- `action: git_upload_pack` is when someone performs a clone of a repository.
- `action: git_receive_pack` is when someone push's a repository.
- `action: archive` is when someone downloads a repository via the `Download source code` button in the UI.
