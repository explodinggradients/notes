{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d27c522d-c54b-4b4a-9b77-2ab66ca1d315",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "369f3081-e620-4080-a780-a6437eabf406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349222a1-0d46-40f2-873c-fc21ea6309b2",
   "metadata": {},
   "source": [
    "# Improving the Retriever\n",
    "\n",
    "things we are going to try\n",
    "- different embeddedding (with fastembed and openai):\n",
    "- reranker (cohere)\n",
    "- Multi-Query Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42ed4d8-e589-46b2-b70e-1331eac0756e",
   "metadata": {},
   "source": [
    "## Building the VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45c4ab98-0a15-4719-b8ec-0c3b467b1db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "loader = DirectoryLoader(\"./data/\")\n",
    "documents = loader.load()\n",
    "\n",
    "for document in documents:\n",
    "    document.metadata['file_name'] = document.metadata['source']\n",
    "\n",
    "docs = documents\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36709249-b80b-42dd-b6c7-768ccbd2ceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, \n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bb2b432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Example(dataset_id=UUID('8f267706-24b2-47fb-84ee-3ea3cfc5a0c0'), inputs={'question': 'How do the cycles at 37signals affect communication and decision-making?'}, outputs={'ground_truth': 'The cycles at 37signals help to create a fixed cadence and provide a regular interval for decision-making. They also help to prioritize work and break big projects into smaller ones. The communication mechanisms, such as daily and weekly check-ins, heartbeats, and kickoffs, ensure that everyone is kept in the loop about the work being done.'}, id=UUID('771183c7-5ff6-4fde-bef0-8e999de218e1'), created_at=datetime.datetime(2024, 3, 6, 20, 31, 43, 147801, tzinfo=datetime.timezone.utc), modified_at=datetime.datetime(2024, 3, 6, 20, 31, 43, 147801, tzinfo=datetime.timezone.utc), runs=[], source_run_id=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "examples = list(client.list_examples(dataset_name=\"basecamp\"))\n",
    "\n",
    "examples[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4f55cb-3d06-441d-81e5-b33da4598f39",
   "metadata": {},
   "source": [
    "## Experiment 1:  Try out different Embeddings\n",
    "\n",
    "lets evaluate between\n",
    "- ada2\n",
    "- BGE\n",
    "- OpenAI's new `text-embedding-3-large`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96c54b02-edd0-4a7d-9572-90d3d7813c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ada\n",
    "vectorstore_ada = Chroma.from_documents(\n",
    "    documents=splits, \n",
    "    embedding=OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e81c9b5-8885-477b-841c-6ccb97804759",
   "metadata": {},
   "source": [
    "Lets build a reference RAG with this embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5438fb85-c49a-4ea6-9402-f10bd7af1f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough, RunnableParallel\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2e14a96e-b039-445c-b176-d436c8ebd531",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore_retriever = vectorstore_ada.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "\n",
    "def format_retriever(input_dict):\n",
    "    # if dict or list\n",
    "    if isinstance(input_dict, dict):\n",
    "        docs = input_dict[\"contexts\"]\n",
    "    else:\n",
    "        docs = input_dict\n",
    "\n",
    "    # get the text in each chunk\n",
    "    doc_strs = []\n",
    "    for d in docs:\n",
    "        if isinstance(d, str):\n",
    "            doc_strs.append(d)\n",
    "        else:\n",
    "            doc_strs.append(d.page_content)\n",
    "\n",
    "    # join and send the rest\n",
    "    return {\n",
    "        \"question\": input_dict[\"question\"],\n",
    "        \"context\": \"\\n\\n\".join(doc_strs)\n",
    "    }\n",
    "    \n",
    "def ragas_output_parser(input):\n",
    "    if isinstance(input, list):\n",
    "        return [doc.page_content for doc in input]\n",
    "    elif isinstance(input, dict):\n",
    "        docs = input[\"contexts\"]\n",
    "        return [doc.page_content for doc in docs]\n",
    "\n",
    "def passthrough(column_name):\n",
    "   return RunnableLambda(lambda x: x.get(column_name) if isinstance(x, dict) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "19b371d5-2376-4da7-9406-4e3542a3e0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "generator = (\n",
    "    prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "def retriver_factory(retriever):\n",
    "    retriever = RunnableParallel({\n",
    "        \"contexts\": passthrough(\"question\") | retriever | ragas_output_parser, \n",
    "        \"question\": passthrough(\"question\")\n",
    "    })\n",
    "\n",
    "    return retriever\n",
    "\n",
    "filter_langsmith_dataset = RunnableLambda(lambda x: x[\"question\"] if isinstance(x, dict) else x)\n",
    "\n",
    "def rag_factory(vector_store=None, retriever = None):\n",
    "    if vector_store is not None:\n",
    "        retriever = vector_store.as_retriever()\n",
    "    elif retriever is not None:\n",
    "        retriever = retriever\n",
    "    else:\n",
    "        raise ValueError(\"You must provide a vectorstore or a retriever\")\n",
    "    rag_chain_ada = (\n",
    "        filter_langsmith_dataset |\n",
    "        retriver_factory(retriever) |\n",
    "        RunnableParallel({\n",
    "            \"answer\": format_retriever | generator,\n",
    "            \"contexts\": RunnablePassthrough()\n",
    "        })\n",
    "    )\n",
    "    return rag_chain_ada\n",
    "\n",
    "rag_chain_ada = rag_factory(vectorstore_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ac950aa6-7799-42b0-91e0-6baf829621ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How do the cycles at 37signals affect communication and decision-making?'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = examples[0].inputs\n",
    "q[\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bd1c5795-e7ee-4361-9f4d-bf7f39b4888e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The cycles at 37signals create a sense of urgency and help prevent projects from becoming too large. They also provide a regular interval for decision-making on what to work on. Communication is facilitated through daily and weekly questions about work progress and intentions.'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer = RunnableLambda(lambda x: x[\"answer\"])\n",
    "(rag_factory(vectorstore_ada) | get_answer).invoke(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b034542",
   "metadata": {},
   "source": [
    "### BGE Embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "673dd5fb-590e-459a-9824-1154a17b37d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-13 17:12:55.547\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfastembed.embedding\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[33m\u001b[1mDefaultEmbedding, FlagEmbedding, JinaEmbedding are deprecated.Use from fastembed import TextEmbedding instead.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c517a0e19684cc3b740b851a48e7b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# BGE\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "vectorstore_bge = Chroma.from_documents(\n",
    "    collection_name=\"bge\",\n",
    "    documents=splits, \n",
    "    embedding=FastEmbedEmbeddings(model_name=\"BAAI/bge-large-en-v1.5\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1acb1a3-e690-4587-b7e9-911bffae2cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The cycles at 37signals create a sense of urgency and help prevent projects from becoming too large. They also provide a regular interval for decision-making on what to work on. Communication is facilitated through daily and weekly questions about work progress and intentions.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make the rag\n",
    "bge_rag = rag_factory(vectorstore_bge)\n",
    "\n",
    "(bge_rag | get_answer).invoke(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac07e39",
   "metadata": {},
   "source": [
    "### OpenAI's Text Embedding 3 Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c84b54af-ed7d-49e4-9302-c52382f542be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text-embedding\n",
    "vectorstore_text_embedding = Chroma.from_documents(\n",
    "    collection_name=\"text-emb-3-lg\",\n",
    "    documents=splits, \n",
    "    embedding=OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3cce5031-18f4-4f0c-881b-6647ecf30bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The cycles at 37signals create a sense of urgency and help prevent projects from becoming too large. They also provide a regular interval for decision-making on what projects to work on. Communication is facilitated through daily and weekly questions about work progress and intentions.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make the rag\n",
    "text_embed_rag = rag_factory(vectorstore_text_embedding)\n",
    "\n",
    "(text_embed_rag | get_answer).invoke(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6957360-e643-4d02-b09f-b7ff76341121",
   "metadata": {},
   "source": [
    "## Evaluation of the different embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6a24c7d0-6df5-4fd4-ab69-52dcc9aa790e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.integrations.langchain import EvaluatorChain\n",
    "from ragas.integrations.langsmith import evaluate\n",
    "\n",
    "# import the metrics we will need\n",
    "from ragas.metrics import context_precision, context_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec2a658f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'ada' at:\n",
      "https://smith.langchain.com/o/9bfbddc5-b88e-41e5-92df-2a62f0c64b4b/datasets/8f267706-24b2-47fb-84ee-3ea3cfc5a0c0/compare?selectedSessions=60f28e99-82b0-4a32-9ec8-8cfae59ac7da\n",
      "\n",
      "View all tests for Dataset basecamp at:\n",
      "https://smith.langchain.com/o/9bfbddc5-b88e-41e5-92df-2a62f0c64b4b/datasets/8f267706-24b2-47fb-84ee-3ea3cfc5a0c0\n",
      "[>                                                 ] 0/7"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjmachan/.pyenv/versions/3.10.12/envs/notes/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------->                                    ] 2/7"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid JSON response. Expected dictionary with key 'Attributed'\n",
      "Failed to batch ingest runs: LangSmithError('Failed to post https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'400 Client Error: Bad Request for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Request body is not valid JSON\"}\\')')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------------------------------------->] 7/7"
     ]
    }
   ],
   "source": [
    "# retriever with Ada embeddings\n",
    "ada_retriever = retriver_factory(vectorstore_ada)\n",
    "\n",
    "run = evaluate(\n",
    "    experiment_name=\"ada\",\n",
    "    dataset_name=\"basecamp\", \n",
    "    llm_or_chain_factory=retriver_factory(vectorstore_ada), \n",
    "    metrics=[context_precision, context_recall],\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c2af9105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'bge_retriever' at:\n",
      "https://smith.langchain.com/o/9bfbddc5-b88e-41e5-92df-2a62f0c64b4b/datasets/8f267706-24b2-47fb-84ee-3ea3cfc5a0c0/compare?selectedSessions=efc8c7d0-5517-4d9d-abfc-0427dbe2b86a\n",
      "\n",
      "View all tests for Dataset basecamp at:\n",
      "https://smith.langchain.com/o/9bfbddc5-b88e-41e5-92df-2a62f0c64b4b/datasets/8f267706-24b2-47fb-84ee-3ea3cfc5a0c0\n",
      "[------------------------------------------------->] 7/7"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Experiment Results:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback.context_precision</th>\n",
       "      <th>feedback.context_recall</th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b3dd731c-22ca-49e4-abf1-d86e5618aa9b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.476688</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.374007</td>\n",
       "      <td>0.188982</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.249074</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.144702</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.260192</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.643713</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.668870</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690279</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feedback.context_precision  feedback.context_recall error  \\\n",
       "count                     7.000000                 7.000000     0   \n",
       "unique                         NaN                      NaN     0   \n",
       "top                            NaN                      NaN   NaN   \n",
       "freq                           NaN                      NaN   NaN   \n",
       "mean                      0.793651                 0.928571   NaN   \n",
       "std                       0.374007                 0.188982   NaN   \n",
       "min                       0.000000                 0.500000   NaN   \n",
       "25%                       0.777778                 1.000000   NaN   \n",
       "50%                       1.000000                 1.000000   NaN   \n",
       "75%                       1.000000                 1.000000   NaN   \n",
       "max                       1.000000                 1.000000   NaN   \n",
       "\n",
       "        execution_time                                run_id  \n",
       "count         7.000000                                     7  \n",
       "unique             NaN                                     7  \n",
       "top                NaN  b3dd731c-22ca-49e4-abf1-d86e5618aa9b  \n",
       "freq               NaN                                     1  \n",
       "mean          0.476688                                   NaN  \n",
       "std           0.249074                                   NaN  \n",
       "min           0.144702                                   NaN  \n",
       "25%           0.260192                                   NaN  \n",
       "50%           0.643713                                   NaN  \n",
       "75%           0.668870                                   NaN  \n",
       "max           0.690279                                   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# retriever with BGE embeddings\n",
    "bge_retriever = retriver_factory(vectorstore_bge)\n",
    "\n",
    "run = evaluate(\n",
    "    experiment_name=\"bge_retriever\",\n",
    "    dataset_name=\"basecamp\", \n",
    "    llm_or_chain_factory=bge_retriever, \n",
    "    metrics=[context_precision, context_recall],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "74d04cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'text_embedding_3_retriver' at:\n",
      "https://smith.langchain.com/o/9bfbddc5-b88e-41e5-92df-2a62f0c64b4b/datasets/8f267706-24b2-47fb-84ee-3ea3cfc5a0c0/compare?selectedSessions=ad669381-ced0-4a1f-ae3c-45d4f852c902\n",
      "\n",
      "View all tests for Dataset basecamp at:\n",
      "https://smith.langchain.com/o/9bfbddc5-b88e-41e5-92df-2a62f0c64b4b/datasets/8f267706-24b2-47fb-84ee-3ea3cfc5a0c0\n",
      "[------------------------------------------>       ] 6/7"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid JSON response. Expected dictionary with key 'Attributed'\n",
      "Failed to batch ingest runs: LangSmithError('Failed to post https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'400 Client Error: Bad Request for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Request body is not valid JSON\"}\\')')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------------------------------------->] 7/7"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Experiment Results:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback.context_precision</th>\n",
       "      <th>feedback.context_recall</th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88b94785-b177-48ec-843a-4b8c1c036713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.948413</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.439906</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.088466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.130925</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.805556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.272072</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.363577</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.432972</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.516501</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614142</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feedback.context_precision  feedback.context_recall error  \\\n",
       "count                     7.000000                      6.0     0   \n",
       "unique                         NaN                      NaN     0   \n",
       "top                            NaN                      NaN   NaN   \n",
       "freq                           NaN                      NaN   NaN   \n",
       "mean                      0.948413                      1.0   NaN   \n",
       "std                       0.088466                      0.0   NaN   \n",
       "min                       0.805556                      1.0   NaN   \n",
       "25%                       0.916667                      1.0   NaN   \n",
       "50%                       1.000000                      1.0   NaN   \n",
       "75%                       1.000000                      1.0   NaN   \n",
       "max                       1.000000                      1.0   NaN   \n",
       "\n",
       "        execution_time                                run_id  \n",
       "count         7.000000                                     7  \n",
       "unique             NaN                                     7  \n",
       "top                NaN  88b94785-b177-48ec-843a-4b8c1c036713  \n",
       "freq               NaN                                     1  \n",
       "mean          0.439906                                   NaN  \n",
       "std           0.130925                                   NaN  \n",
       "min           0.272072                                   NaN  \n",
       "25%           0.363577                                   NaN  \n",
       "50%           0.432972                                   NaN  \n",
       "75%           0.516501                                   NaN  \n",
       "max           0.614142                                   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# retriever with text-embedding embeddings\n",
    "text_embedding_retriever = retriver_factory(vectorstore_text_embedding)\n",
    "\n",
    "run = evaluate(\n",
    "    experiment_name=\"text_embedding_3_retriver\",\n",
    "    dataset_name=\"basecamp\", \n",
    "    llm_or_chain_factory=text_embedding_retriever, \n",
    "    metrics=[context_precision, context_recall],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4427783",
   "metadata": {},
   "source": [
    "# Experiment 2: Using a ReRanker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "49185bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for printing docs\n",
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eb378452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "How We Work\n",
      "\n",
      "Cycles\n",
      "\n",
      "We work in 6-week or 8-week cycles at 37signals. There are typically six cycles to a year. Two are 8-week cycles, during Summer Hours, and the rest 6-week cycles. This fixed cadence serves to give us an internal sense of urgency, work as a scope hammer to keep projects from ballooning, and provide a regular interval to decide what we’re working on.\n",
      "\n",
      "The idea is not that everything we ever decide to work on has to take six or eight weeks or can be completed in that time. But rather that we think about how we can break big projects into smaller ones that can be done in that amount of time, and that we bundle smaller things into a presentable scope of work that can be discussed.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Communication\n",
      "\n",
      "It’s hard to keep up on what everyone is doing and what it means, if you just watch the stream of latest activity scrolling along in 37signals. (It’s also a waste of time and source of stress to even try.) Instead, we have four chief mechanisms for keeping everyone in the loop about the work that’s going on.\n",
      "\n",
      "First, there’s the daily question of What did you work on today?, which supplies the nitty gritty details, but as a personal narrative. They’re a great conversation starter if you see someone working on something you either care about or want to learn more about. Please do use them as such! You’re obliged to answer this question at least twice a week.\n",
      "\n",
      "Second, there’s the weekly question of What will you be working on this week?, which details your intentions for the coming week. Everyone except team OMG is obliged to answer this question when they’re not out.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "While a few pitches might instantly strike a chord loud enough to go on the plate for the next cycle, it’s more likely that your pitch will sit for a while first. There are always more ideas than time, and we can only get a few things done each cycle. So chances are that even if everyone agrees the pitch is a great idea, it might not be the next most important thing for us to tackle. Don’t be discouraged by this. We’ve had many pitches that have sat for many cycles, if not years, before finally coming together and then happening.\n",
      "\n",
      "Asynchronously\n",
      "\n",
      "We have people working all sorts of different hours and from all sorts of different places at 37signals. That alone makes it hard to enforce a lot of tightly-coupled workflows during the day, but that’s a feature not a bug. Most of the work you do at 37signals shouldn’t require you to be in constant communication throughout the entire day with someone.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "These mechanisms work together to free individuals and teams to run their days and cycles with confidence and independence. We have six opportunities per year to make big decisions about what to work on, and the rest of the time should chiefly be spent carrying out those short-term plans. By having clear expectations for communication, it’s easier for everyone to build trust in where we’re going and why.\n",
      "\n",
      "All these questions and write-ups will be posted in the What Works project for the current year.\n",
      "\n",
      "Pitches\n",
      "\n",
      "Whether you work on the product development or not, your voice and observations can help determine what we should be working on. The way to exert this influence is through pitches.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 5:\n",
      "\n",
      "So, this is where we’ll try to share what’s worth knowing about 37signals the company, our culture, our process, and our history. It’s a guide to understanding what people are talking about when they call for “judo” (redefining a hard problem into an easy one) or whether it’s okay to take your vacation when you’ve only been with us for a month (yes).\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 6:\n",
      "\n",
      "What Influenced Us\n",
      "\n",
      "If you want to learn the 37signals view of the world, it helps to know the influences that helped form it. We’ve been around since 1999. Since then there’s been a number of key influencers that have marked the company culture.\n",
      "\n",
      "Books\n",
      "\n",
      "Turn The Ship Around: “Leadership should mean giving control rather than taking control and creating leaders rather than forging followers”, David Marquet. 37signals employs great people and they deserve the freedom and autonomy to act on their own. Don’t wait for permission, just state what you’re going to do, and then do it.\n",
      "\n",
      "Finding Flow: True happiness is found in optimal moments of engagement when we stretch just beyond our abilities and lose track of time and space in the process. Protecting the flow by limiting interruptions has been a driving principle of 37signals.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 7:\n",
      "\n",
      "But let’s take a look back. In 2003, 37signals was a web design firm made up of 4 people. We always had work, but we were disorganized. With so many concurrent projects, things began to slip through the cracks. Projects dragged on too long. We dropped the ball on key deliverables. We had some major miscommunication. As many people even still do, we relied on email for everything. Things inevitably got lost, people get left out of conversations, there’s nowhere to go to see what’s left to do.\n",
      "\n",
      "So we started looking for a project management tool. We tried a few tools, but they were complicated and didn’t fit what we needed. Frustrated, we decided to build our own simple project management app. A few months later we had something ready, and we immediately started using this tool with our existing clients.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 8:\n",
      "\n",
      "With managers of one\n",
      "\n",
      "We rely on everyone at 37signals to do a lot of self-management. People who do this well qualify as managers of one, and we strive for everyone senior or above to embody this principle fully.\n",
      "\n",
      "That means setting your own direction when one isn’t given. Determining what needs to be done, and doing it, without waiting for someone to tell you to. A manager of one will spend their time well when left to their own devices. There’s always more work to be done, always more initiatives to kick off, always more improvement to be had.\n",
      "\n",
      "Balanced\n",
      "\n",
      "We limit ourselves to a 40-hour (32-hour in the summer) work week. Keeping our hours at work limited forces us to prioritize the work that really matters. A healthy amount of sleep and a rich and rewarding life outside of work should not be squandered for a few more hours at work.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 9:\n",
      "\n",
      "Cooldown\n",
      "\n",
      "In between each cycle, we spend two weeks cooling down. That’s the time to deal with bugs or smaller issues that come up, write up what we worked on, and figure out what we should tackle next. It’s sometimes tempting to simply extend the cycles into the cooldown period to fit in more work. But the goal is to resist this temptation. Yes, sometimes a little spill-over will happen, but it’s helpful to think about the end of the normal cycle as “pencils down”. That means that by week 4 of a normal cycle, we should be winding down, getting ready to launch, make sure QA is lined up, and all the other work that happens during and after the launch of new projects.\n",
      "\n",
      "Communication\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 10:\n",
      "\n",
      "Daily and weekly check-ins are subdivided by department so you’re only subscribed to your team’s answers. You’re of course free to subscribe to other team check-ins, but you’re not obligated to do so if you find it too noisy.\n",
      "\n",
      "Third, there are the heartbeats. These are the team versions of What did you work on this cycle? This is where we summarize and celebrate the work that’s been done. Every team lead is obliged to write, or designate someone on the team to write, this account one week after a cycle has ended.\n",
      "\n",
      "Fourth, and finally, there are the kickoffs. These are the team version of What are you going to work on next cycle? This is where the plan for the coming six or eight weeks is presented. Every team lead is obliged to write, or designate someone on the team to write, this account before the start of the new cycle.\n"
     ]
    }
   ],
   "source": [
    "ret = vectorstore_text_embedding.as_retriever(search_kwargs={\"k\": 10})\n",
    "docs = ret.get_relevant_documents(q[\"question\"])\n",
    "pretty_print_docs(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "88081a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors.cohere_rerank import CohereRerank\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "compressor = CohereRerank()\n",
    "vectorstore_text_embedding.as_retriever\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, \n",
    "    base_retriever=vectorstore_text_embedding.as_retriever(search_kwargs={\"k\": 10})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2527d5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "How We Work\n",
      "\n",
      "Cycles\n",
      "\n",
      "We work in 6-week or 8-week cycles at 37signals. There are typically six cycles to a year. Two are 8-week cycles, during Summer Hours, and the rest 6-week cycles. This fixed cadence serves to give us an internal sense of urgency, work as a scope hammer to keep projects from ballooning, and provide a regular interval to decide what we’re working on.\n",
      "\n",
      "The idea is not that everything we ever decide to work on has to take six or eight weeks or can be completed in that time. But rather that we think about how we can break big projects into smaller ones that can be done in that amount of time, and that we bundle smaller things into a presentable scope of work that can be discussed.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "While a few pitches might instantly strike a chord loud enough to go on the plate for the next cycle, it’s more likely that your pitch will sit for a while first. There are always more ideas than time, and we can only get a few things done each cycle. So chances are that even if everyone agrees the pitch is a great idea, it might not be the next most important thing for us to tackle. Don’t be discouraged by this. We’ve had many pitches that have sat for many cycles, if not years, before finally coming together and then happening.\n",
      "\n",
      "Asynchronously\n",
      "\n",
      "We have people working all sorts of different hours and from all sorts of different places at 37signals. That alone makes it hard to enforce a lot of tightly-coupled workflows during the day, but that’s a feature not a bug. Most of the work you do at 37signals shouldn’t require you to be in constant communication throughout the entire day with someone.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "Communication\n",
      "\n",
      "It’s hard to keep up on what everyone is doing and what it means, if you just watch the stream of latest activity scrolling along in 37signals. (It’s also a waste of time and source of stress to even try.) Instead, we have four chief mechanisms for keeping everyone in the loop about the work that’s going on.\n",
      "\n",
      "First, there’s the daily question of What did you work on today?, which supplies the nitty gritty details, but as a personal narrative. They’re a great conversation starter if you see someone working on something you either care about or want to learn more about. Please do use them as such! You’re obliged to answer this question at least twice a week.\n",
      "\n",
      "Second, there’s the weekly question of What will you be working on this week?, which details your intentions for the coming week. Everyone except team OMG is obliged to answer this question when they’re not out.\n"
     ]
    }
   ],
   "source": [
    "compressed_docs = compression_retriever.get_relevant_documents(q[\"question\"])\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "19b14afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The cycles at 37signals provide a fixed cadence for decision-making and project scope. They help break big projects into smaller ones that can be completed in a set amount of time. Communication is facilitated through daily and weekly questions to keep everyone in the loop about the work being done.'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_with_reranker = rag_factory(retriever=compression_retriever)\n",
    "(rag_with_reranker | get_answer).invoke(q)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "37962e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'reranker' at:\n",
      "https://smith.langchain.com/o/9bfbddc5-b88e-41e5-92df-2a62f0c64b4b/datasets/8f267706-24b2-47fb-84ee-3ea3cfc5a0c0/compare?selectedSessions=127a0557-51f5-4f02-908a-bbc5502058ed\n",
      "\n",
      "View all tests for Dataset basecamp at:\n",
      "https://smith.langchain.com/o/9bfbddc5-b88e-41e5-92df-2a62f0c64b4b/datasets/8f267706-24b2-47fb-84ee-3ea3cfc5a0c0\n",
      "[-------------------->                             ] 3/7"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid JSON response. Expected dictionary with key 'Attributed'\n",
      "Failed to batch ingest runs: LangSmithError('Failed to post https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'400 Client Error: Bad Request for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Request body is not valid JSON\"}\\')')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[---------------------------->                     ] 4/7"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid JSON response. Expected dictionary with key 'Attributed'\n",
      "Failed to batch ingest runs: LangSmithError('Failed to post https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'400 Client Error: Bad Request for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Request body is not valid JSON\"}\\')')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------------------------------>       ] 6/7"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid JSON response. Expected dictionary with key 'Attributed'\n",
      "Failed to batch ingest runs: LangSmithError('Failed to post https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'400 Client Error: Bad Request for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Request body is not valid JSON\"}\\')')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------------------------------------->] 7/7"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Experiment Results:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback.context_precision</th>\n",
       "      <th>feedback.context_recall</th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6fde9b65-8174-4fa1-8441-9dee884f23a0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.534166</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.534522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.437899</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.776245</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.398282</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.570000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.694026</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.208302</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feedback.context_precision  feedback.context_recall error  \\\n",
       "count                     7.000000                      4.0     0   \n",
       "unique                         NaN                      NaN     0   \n",
       "top                            NaN                      NaN   NaN   \n",
       "freq                           NaN                      NaN   NaN   \n",
       "mean                      0.428571                      1.0   NaN   \n",
       "std                       0.534522                      0.0   NaN   \n",
       "min                       0.000000                      1.0   NaN   \n",
       "25%                       0.000000                      1.0   NaN   \n",
       "50%                       0.000000                      1.0   NaN   \n",
       "75%                       1.000000                      1.0   NaN   \n",
       "max                       1.000000                      1.0   NaN   \n",
       "\n",
       "        execution_time                                run_id  \n",
       "count         7.000000                                     7  \n",
       "unique             NaN                                     7  \n",
       "top                NaN  6fde9b65-8174-4fa1-8441-9dee884f23a0  \n",
       "freq               NaN                                     1  \n",
       "mean          2.534166                                   NaN  \n",
       "std           0.437899                                   NaN  \n",
       "min           1.776245                                   NaN  \n",
       "25%           2.398282                                   NaN  \n",
       "50%           2.570000                                   NaN  \n",
       "75%           2.694026                                   NaN  \n",
       "max           3.208302                                   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = evaluate(\n",
    "    experiment_name=\"reranker\",\n",
    "    dataset_name=\"basecamp\", \n",
    "    llm_or_chain_factory=rag_with_reranker, \n",
    "    metrics=[context_precision, context_recall],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08fad52",
   "metadata": {},
   "source": [
    "# Experiment 3: Multi-Query Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ebace76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How do the cycles at 37signals affect communication and decision-making?'}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "682f2f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "multi_query_ret = MultiQueryRetriever.from_llm(\n",
    "    retriever=vectorstore_text_embedding.as_retriever(), \n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "46d336a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "How We Work\n",
      "\n",
      "Cycles\n",
      "\n",
      "We work in 6-week or 8-week cycles at 37signals. There are typically six cycles to a year. Two are 8-week cycles, during Summer Hours, and the rest 6-week cycles. This fixed cadence serves to give us an internal sense of urgency, work as a scope hammer to keep projects from ballooning, and provide a regular interval to decide what we’re working on.\n",
      "\n",
      "The idea is not that everything we ever decide to work on has to take six or eight weeks or can be completed in that time. But rather that we think about how we can break big projects into smaller ones that can be done in that amount of time, and that we bundle smaller things into a presentable scope of work that can be discussed.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Communication\n",
      "\n",
      "It’s hard to keep up on what everyone is doing and what it means, if you just watch the stream of latest activity scrolling along in 37signals. (It’s also a waste of time and source of stress to even try.) Instead, we have four chief mechanisms for keeping everyone in the loop about the work that’s going on.\n",
      "\n",
      "First, there’s the daily question of What did you work on today?, which supplies the nitty gritty details, but as a personal narrative. They’re a great conversation starter if you see someone working on something you either care about or want to learn more about. Please do use them as such! You’re obliged to answer this question at least twice a week.\n",
      "\n",
      "Second, there’s the weekly question of What will you be working on this week?, which details your intentions for the coming week. Everyone except team OMG is obliged to answer this question when they’re not out.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "While a few pitches might instantly strike a chord loud enough to go on the plate for the next cycle, it’s more likely that your pitch will sit for a while first. There are always more ideas than time, and we can only get a few things done each cycle. So chances are that even if everyone agrees the pitch is a great idea, it might not be the next most important thing for us to tackle. Don’t be discouraged by this. We’ve had many pitches that have sat for many cycles, if not years, before finally coming together and then happening.\n",
      "\n",
      "Asynchronously\n",
      "\n",
      "We have people working all sorts of different hours and from all sorts of different places at 37signals. That alone makes it hard to enforce a lot of tightly-coupled workflows during the day, but that’s a feature not a bug. Most of the work you do at 37signals shouldn’t require you to be in constant communication throughout the entire day with someone.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "What Influenced Us\n",
      "\n",
      "If you want to learn the 37signals view of the world, it helps to know the influences that helped form it. We’ve been around since 1999. Since then there’s been a number of key influencers that have marked the company culture.\n",
      "\n",
      "Books\n",
      "\n",
      "Turn The Ship Around: “Leadership should mean giving control rather than taking control and creating leaders rather than forging followers”, David Marquet. 37signals employs great people and they deserve the freedom and autonomy to act on their own. Don’t wait for permission, just state what you’re going to do, and then do it.\n",
      "\n",
      "Finding Flow: True happiness is found in optimal moments of engagement when we stretch just beyond our abilities and lose track of time and space in the process. Protecting the flow by limiting interruptions has been a driving principle of 37signals.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 5:\n",
      "\n",
      "So, this is where we’ll try to share what’s worth knowing about 37signals the company, our culture, our process, and our history. It’s a guide to understanding what people are talking about when they call for “judo” (redefining a hard problem into an easy one) or whether it’s okay to take your vacation when you’ve only been with us for a month (yes).\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 6:\n",
      "\n",
      "These mechanisms work together to free individuals and teams to run their days and cycles with confidence and independence. We have six opportunities per year to make big decisions about what to work on, and the rest of the time should chiefly be spent carrying out those short-term plans. By having clear expectations for communication, it’s easier for everyone to build trust in where we’re going and why.\n",
      "\n",
      "All these questions and write-ups will be posted in the What Works project for the current year.\n",
      "\n",
      "Pitches\n",
      "\n",
      "Whether you work on the product development or not, your voice and observations can help determine what we should be working on. The way to exert this influence is through pitches.\n"
     ]
    }
   ],
   "source": [
    "docs = multi_query_ret.get_relevant_documents(q[\"question\"])\n",
    "pretty_print_docs(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b8e3c792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The cycles at 37signals create a sense of urgency and help prevent projects from becoming too large. Communication is facilitated through daily and weekly questions to keep everyone in the loop about the work being done. Pitches play a role in decision-making, with some ideas taking multiple cycles to come to fruition.'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_query_rag = rag_factory(retriever=multi_query_ret)\n",
    "(multi_query_rag | get_answer).invoke(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9bb44d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'mulit_query' at:\n",
      "https://smith.langchain.com/o/9bfbddc5-b88e-41e5-92df-2a62f0c64b4b/datasets/8f267706-24b2-47fb-84ee-3ea3cfc5a0c0/compare?selectedSessions=581dd7af-7bae-4242-bb78-a137e2355898\n",
      "\n",
      "View all tests for Dataset basecamp at:\n",
      "https://smith.langchain.com/o/9bfbddc5-b88e-41e5-92df-2a62f0c64b4b/datasets/8f267706-24b2-47fb-84ee-3ea3cfc5a0c0\n",
      "[------>                                           ] 1/7"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid JSON response. Expected dictionary with key 'Attributed'\n",
      "Invalid JSON response. Expected dictionary with key 'Attributed'\n",
      "Failed to batch ingest runs: LangSmithError('Failed to post https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'400 Client Error: Bad Request for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Request body is not valid JSON\"}\\')')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-------------------->                             ] 3/7"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid JSON response. Expected dictionary with key 'Attributed'\n",
      "Failed to batch ingest runs: LangSmithError('Failed to post https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'400 Client Error: Bad Request for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Request body is not valid JSON\"}\\')')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[---------------------------->                     ] 4/7"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid JSON response. Expected dictionary with key 'Attributed'\n",
      "Failed to batch ingest runs: LangSmithError('Failed to post https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'400 Client Error: Bad Request for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Request body is not valid JSON\"}\\')')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------------------------------>       ] 6/7"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid JSON response. Expected dictionary with key 'Attributed'\n",
      "Failed to batch ingest runs: LangSmithError('Failed to post https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'400 Client Error: Bad Request for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Request body is not valid JSON\"}\\')')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------------------------------------->] 7/7"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Experiment Results:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback.context_precision</th>\n",
       "      <th>feedback.context_recall</th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bce40e6c-d7b5-4fe2-9bf6-234bba353c21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.735159</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.534522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.981516</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.859380</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.989503</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.533062</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.192072</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.390519</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feedback.context_precision  feedback.context_recall error  \\\n",
       "count                     7.000000                      2.0     0   \n",
       "unique                         NaN                      NaN     0   \n",
       "top                            NaN                      NaN   NaN   \n",
       "freq                           NaN                      NaN   NaN   \n",
       "mean                      0.571429                      1.0   NaN   \n",
       "std                       0.534522                      0.0   NaN   \n",
       "min                       0.000000                      1.0   NaN   \n",
       "25%                       0.000000                      1.0   NaN   \n",
       "50%                       1.000000                      1.0   NaN   \n",
       "75%                       1.000000                      1.0   NaN   \n",
       "max                       1.000000                      1.0   NaN   \n",
       "\n",
       "        execution_time                                run_id  \n",
       "count         7.000000                                     7  \n",
       "unique             NaN                                     7  \n",
       "top                NaN  bce40e6c-d7b5-4fe2-9bf6-234bba353c21  \n",
       "freq               NaN                                     1  \n",
       "mean          4.735159                                   NaN  \n",
       "std           0.981516                                   NaN  \n",
       "min           3.859380                                   NaN  \n",
       "25%           3.989503                                   NaN  \n",
       "50%           4.533062                                   NaN  \n",
       "75%           5.192072                                   NaN  \n",
       "max           6.390519                                   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = evaluate(\n",
    "    experiment_name=\"mulit_query\",\n",
    "    dataset_name=\"basecamp\", \n",
    "    llm_or_chain_factory=multi_query_rag, \n",
    "    metrics=[context_precision, context_recall],\n",
    "    verbose=True\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
